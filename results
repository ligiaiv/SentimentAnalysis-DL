04/09/2018 - 08:57
-Testado apenas a DB de Jorge Amado, utilizando uma LSTM Bidirecional
Glove s100
EMBEDDING_DIM = 100
MAX_VOCAB_SIZE = 30000
possible_labels = ["+","O","-"]
MAX_SEQUENCE_LENGTH = 100
VALIDATION_SPLIT = 0.2
BATCH_SIZE = 128
EPOCHS = 100

Resultados:
244/244 [==============================] - 0s 987us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.6153 - val_acc: 0.7978
Gráfico:  Figura_1.png

-Feito exatamente o mesmo teste, porém com LSTM normal

Resultados:
244/244 [==============================] - 0s 581us/step - loss: 0.0435 - acc: 0.9891 - val_loss: 0.7827 - val_acc: 0.7322
Gráfico: Figura_2.png

-Feitos os mesmos experimentos porém com todo o DataSet
--LSTM:
		1848/1848 [==============================] - 1s 596us/step - loss: 0.0376 - acc: 0.9908 - val_loss: 1.0862 - val_acc: 0.7439
		Gráfico: Figura_3.png

--BiLSTM:
		1848/1848 [==============================] - 2s 1ms/step - loss: 0.2138 - acc: 0.9197 - val_loss: 0.7173 - val_acc: 0.7561
		Gráfico: Figura_4.png

		OBS: No final o val_acc apresentou uma queda brusca
			Achar uma maneira de parar o processo antes

﻿04/09/2018 - 08:57
Testando com todo o Dataset com Embedding de dim=300
x = Bidirectional(LSTM(15,return_sequences = True))(x)

EMBEDDING_DIM = 300
MAX_VOCAB_SIZE = 30000
possible_labels = ["+","O","-"]
MAX_SEQUENCE_LENGTH = 100
VALIDATION_SPLIT = 0.2
BATCH_SIZE = 128
EPOCHS = 100

1848/1848 [==============================] - 4s 2ms/step - loss: 0.0145 - acc: 0.9935 - val_loss: 0.8579 - val_acc: 0.7929

após aproximadamente 5 épocas acurácia atingiu o seu máximo, de aproximadamente 81%

-Feito mesmo teste, porém com 10 épocas

Gráfico: Figura-Corvo-1.png
1848/1848 [==============================] - 4s 2ms/step - loss: 0.1754 - acc: 0.9497 - val_loss: 0.4608 - val_acc: 0.7893

-Exatamente o mesmo teste, porém calculando a acurácia sobre todo o conjunto:

1848/1848 [==============================] - 4s 2ms/step - loss: 0.1669 - acc: 0.9455 - val_loss: 0.4564 - val_acc: 0.8160
0.9613426736577582

-Mesmo experimento, porém com 30 camadas

dbFile = "BigFiles/ReLi-Completo.txt"
EMBEDDING_DIM = 300
MAX_VOCAB_SIZE = 30000
possible_labels = ["+","O","-"]
MAX_SEQUENCE_LENGTH = 100
VALIDATION_SPLIT = 0.2
BATCH_SIZE = 128
EPOCHS = 10

1848/1848 [==============================] - 3s 2ms/step - loss: 0.0844 - acc: 0.9794 - val_loss: 0.4966 - val_acc: 0.8175
0.9780074229455193

Gráfico: Figura-Corvo-2.png

-Mesmo teste porém com ebedding de 600 e 15 camadas


dbFile = "BigFiles/ReLi-Completo.txt"
EMBEDDING_DIM = 600
MAX_VOCAB_SIZE = 30000
M = 15 #nº de camadas
possible_labels = ["+","O","-"]
MAX_SEQUENCE_LENGTH = 100
VALIDATION_SPLIT = 0.2
BATCH_SIZE = 128
EPOCHS = 10

Gráfico: Figura-Corvo-3.png

1848/1848 [==============================] - 4s 2ms/step - loss: 0.1005 - acc: 0.9760 - val_loss: 0.4736 - val_acc: 0.8117
0.9750138398526911

Pelo gráfico acho que se colocasse mais épocas poderia melhorar.

-Outro Teste


dbFile = "BigFiles/ReLi-Completo.txt"
EMBEDDING_DIM = 600
MAX_VOCAB_SIZE = 30000
M = 15 #nº de camadas
possible_labels = ["+","O","-"]
MAX_SEQUENCE_LENGTH = 100
VALIDATION_SPLIT = 0.2
BATCH_SIZE = 128
EPOCHS = 40

1848/1848 [==============================] - 4s 2ms/step - loss: 0.0194 - acc: 0.9933 - val_loss: 0.7763 - val_acc: 0.8016
0.9745824863877944

Gráfico: Figura-Corvo-4.png

-Teste com mais camadas e 15 épocas

07 - acc: 0.9921 - val_loss: 0.6864 - val_acc: 0.8001
0.9824737258709871

dbFile = "BigFiles/ReLi-Completo.txt"
EMBEDDING_DIM = 600
MAX_VOCAB_SIZE = 30000
M = 130 #nº de camadas
possible_labels = ["+","O","-"]
MAX_SEQUENCE_LENGTH = 100
VALIDATION_SPLIT = 0.2
BATCH_SIZE = 128
EPOCHS = 15
Gráfico: Figura-Corvo-5.png
